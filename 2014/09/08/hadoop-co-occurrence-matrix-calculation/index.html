<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>以 Hadoop 計算共現矩陣 | Veck's Blog</title><link rel="stylesheet" type="text/css" href="/Veck//css/normalize.css"><link rel="stylesheet" type="text/css" href="/Veck//css/highlight.css"><link rel="stylesheet" type="text/css" href="/Veck//css/very-simple.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/Veck/favicon.ico"></head><body><!-- include the sidebar--><!-- include ./includes/sidebar.jade--><!-- Blog title and subtitle--><header><div class="container header"><a id="logo" href="/Veck/." class="title">Veck's Blog</a><span class="subtitle"></span><label id="toggle-menu" for="menu" onclick><i class="fa fa-bars"></i></label></div></header><!-- use checkbox hack for toggle nav-bar on small screens--><input id="menu" type="checkbox"><!-- Navigation Links--><nav id="nav"><div class="container"><a href="/" class="sidebar-nav-item">Home</a><a href="/Veck/archives" class="sidebar-nav-item">Archives</a></div></nav><div id="header-margin-bar"></div><!-- gallery that comes before the header--><div class="wrapper"><div class="container post-header"><h1>以 Hadoop 計算共現矩陣</h1></div></div><div class="wrapper"><div class="container meta"><div class="post-time">2014-09-08</div></div></div><article><div class="container post"><p>翻譯自原文：<a href="http://codingjunkie.net/cooccurrence/" target="_blank" rel="external">http://codingjunkie.net/cooccurrence/</a></p>
<p>本文是《Data-Intensive Text Processing with MapReduce》提到的 MapReduce 演算法的系列文章的延續。這次我們會使用語料庫建立一個單字共現矩陣。</p>
<p>所謂共現矩陣可以看成是對某件特定事件的追蹤，並給予一段時間或空間窗口(windows，就像作業系統中的排程那樣)，然後記錄還有其他哪些事件也發生了。本文中，我們的『事件(events)』都是文本中個別的『詞(words)』，而我們要追蹤看看(對於某個目標詞)其他哪些詞也在我們設定的窗口條件中出現，我們設定的窗口條件是相對於目標詞彙的位置，例如來看這句話：『The quick brown fox jumped over the lazy dog』，窗口值設為 2，則『jumped』的共現詞是『brown, fox, over, the』。</p>
<p>一個共現矩陣可以應用在很多其他需要找出『當某個事件發生，其他事件似乎也會同時發生』的領域，為了要建構我們的文本共現矩陣，我們需要實作 《Data-Intensive Test Processing with MapReduce》 第三章的 Pairs 和 Stripes 演算法，配合 MapReduce。本文用來建立我們的共現矩陣的文本資料來自於古騰保計畫的<a href="http://www.gutenberg.org/ebooks/100" target="_blank" rel="external">William Shakespear</a>。</p>
<h1 id="Pairs__u6F14_u7B97_u6CD5"><a href="#Pairs__u6F14_u7B97_u6CD5" class="headerlink" title="Pairs 演算法"></a>Pairs 演算法</h1><p>實作 pairs 演算法很簡單。當每次 map 函數被呼叫時傳入一行，便按照空白把傳入的行切割成字串陣列。接著是建立兩層迴圈。外層迴圈迭代陣列中的每個詞，内層迴圈走訪目前這個詞的相鄰詞。内層迴圈的迭代次數取決於需要捕捉的目前詞彙的相鄰距離。在内層迴圈的每次迭代的結束前，我們輸出一個 WordPair 物件（由兩個詞組成，目前的詞在左邊，相鄰詞在右邊）當做 key，這組詞的出現頻率 (one 的次數)當做 value。</p>
<p>以下是 pairs 演算法的程式碼：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class PairsOccurrenceMapper extends Mapper&#60;LongWritable, Text, WordPair, IntWritable&#62; &#123;&#10;    private WordPair wordPair = new WordPair();&#10;    private IntWritable ONE = new IntWritable(1);&#10;&#10;    @Override&#10;    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;&#10;        int neighbors = context.getConfiguration().getInt(&#34;neighbors&#34;, 2);&#10;        String[] tokens = value.toString().split(&#34;\\s+&#34;);&#10;        if (tokens.length &#62; 1) &#123;&#10;          for (int i = 0; i &#60; tokens.length; i++) &#123;&#10;              wordPair.setWord(tokens[i]);&#10;&#10;             int start = (i - neighbors &#60; 0) ? 0 : i - neighbors;&#10;             int end = (i + neighbors &#62;= tokens.length) ? tokens.length - 1 : i + neighbors;&#10;              for (int j = start; j &#60;= end; j++) &#123;&#10;                  if (j == i) continue;&#10;                   wordPair.setNeighbor(tokens[j]);&#10;                   context.write(wordPair, ONE);&#10;              &#125;&#10;          &#125;&#10;      &#125;&#10;  &#125;&#10;&#125;</span><br></pre></td></tr></table></figure></p>
<p>Pairs 演算法中的 Reducer 只是單純的將當做 key 的同一 WordPair 的計數總和：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class PairsReducer extends Reducer&#60;WordPair,IntWritable,WordPair,IntWritable&#62; &#123;&#10;    private IntWritable totalCount = new IntWritable();&#10;    @Override&#10;    protected void reduce(WordPair key, Iterable&#60;IntWritable&#62; values, Context context) throws IOException, InterruptedException &#123;&#10;        int count = 0;&#10;        for (IntWritable value : values) &#123;&#10;             count += value.get();&#10;        &#125;&#10;        totalCount.set(count);&#10;        context.write(key,totalCount);&#10;    &#125;&#10;&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Stripes_u7B97_u6CD5"><a href="#Stripes_u7B97_u6CD5" class="headerlink" title="Stripes算法"></a>Stripes算法</h1><p>共現矩陣中的 stripes 演算法實踐一樣很簡單。不過跟 pairs 演算法不同的是，每個詞的所有相鄰詞被存在一個 hashmap 中，以此相鄰詞 key，詞的出現頻率為 value。當迴圈走訪完每個詞的所有相鄰詞後，這個詞和跟他有關的 hashmap 會被輸出。<br>以下是 stripes 演算法的程式碼：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class StripesOccurrenceMapper extends Mapper&#60;LongWritable,Text,Text,MapWritable&#62; &#123;&#10;  private MapWritable occurrenceMap = new MapWritable();&#10;  private Text word = new Text();&#10;&#10;  @Override&#10; protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;&#10;   int neighbors = context.getConfiguration().getInt(&#34;neighbors&#34;, 2);&#10;   String[] tokens = value.toString().split(&#34;\\s+&#34;);&#10;   if (tokens.length &#62; 1) &#123;&#10;      for (int i = 0; i &#60; tokens.length; i++) &#123;&#10;          word.set(tokens[i]);&#10;          occurrenceMap.clear();&#10;&#10;          int start = (i - neighbors &#60; 0) ? 0 : i - neighbors;&#10;          int end = (i + neighbors &#62;= tokens.length) ? tokens.length - 1 : i + neighbors;&#10;           for (int j = start; j &#60;= end; j++) &#123;&#10;                if (j == i) continue;&#10;                Text neighbor = new Text(tokens[j]);&#10;                if(occurrenceMap.containsKey(neighbor))&#123;&#10;                   IntWritable count = (IntWritable)occurrenceMap.get(neighbor);&#10;                   count.set(count.get()+1);&#10;                &#125;else&#123;&#10;                   occurrenceMap.put(neighbor,new IntWritable(1));&#10;                &#125;&#10;           &#125;&#10;          context.write(word,occurrenceMap);&#10;     &#125;&#10;   &#125;&#10;  &#125;&#10;&#125;</span><br></pre></td></tr></table></figure></p>
<p>Stripe 演算法的 Reducer 有點複雜，因為我們需要迭代過一整個 map 集合，然後對每個 map，再迭代過所有它的 value：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class StripesReducer extends Reducer&#60;Text, MapWritable, Text, MapWritable&#62; &#123;&#10;    private MapWritable incrementingMap = new MapWritable();&#10;&#10;    @Override&#10;    protected void reduce(Text key, Iterable&#60;MapWritable&#62; values, Context context) throws IOException, InterruptedException &#123;&#10;        incrementingMap.clear();&#10;        for (MapWritable value : values) &#123;&#10;            addAll(value);&#10;        &#125;&#10;        context.write(key, incrementingMap);&#10;    &#125;&#10;&#10;    private void addAll(MapWritable mapWritable) &#123;&#10;        Set&#60;Writable&#62; keys = mapWritable.keySet();&#10;        for (Writable key : keys) &#123;&#10;            IntWritable fromCount = (IntWritable) mapWritable.get(key);&#10;            if (incrementingMap.containsKey(key)) &#123;&#10;                IntWritable count = (IntWritable) incrementingMap.get(key);&#10;                count.set(count.get() + fromCount.get());&#10;            &#125; else &#123;&#10;                incrementingMap.put(key, fromCount);&#10;            &#125;&#10;        &#125;&#10;    &#125;&#10;&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="u7D50_u8AD6"><a href="#u7D50_u8AD6" class="headerlink" title="結論"></a>結論</h1><p>比較這兩種演算法，看得出來相較於 Stripes 演算法，Pairs 算法會產生生更多的 key-value pair。而且 Pairs 算法捕捉到的是單一的共現事件，而 Stripes 演算法能夠捕捉到所有的共現事件。Pairs 演算法和 Stripes 演算法的實踐都非常適合使用Combiner。因為這兩種演算法實作產生的結果都是可交换(commutative)與可結合(associative) [*1]，所以我們可以輕易地重用 reducer 作為 Combiner。如前所述，共現矩矩陣不只能應用於文本處理，而且會是 MapReduce 演算法上一個有用的武器。謝謝你的閱讀。</p>
<p>註1: 可使用combiner 的資料必須能夠滿足交換律與結合律<br>註2: Pairs 和 Stripes 分別是兩種不同的共現矩陣演算法</p>
<h1 id="u53C3_u8003_u8CC7_u6599"><a href="#u53C3_u8003_u8CC7_u6599" class="headerlink" title="參考資料"></a>參考資料</h1><ul>
<li>《Data-Intensive Processing with MapReduce》 by Jimmy Lin and Chris Dyer</li>
<li>Hadoop: The Definitive Guide by Tom White</li>
<li>Source Code and Tests from blog</li>
<li>Hadoop API</li>
<li>MRUnit: 用來測試 Apache Hadoop mapreduce</li>
<li>A GitHub Repository: <a href="https://github.com/bbejeck/hadoop-algorithms/tree/master/src/bbejeck/mapred/coocurrance" target="_blank" rel="external">hadoop-algorithm</a></li>
<li>我整合好的另一個專案：<a href="https://github.com/fbukevin/hadoop-cooccurrence" target="_blank" rel="external">https://github.com/fbukevin/hadoop-cooccurrence</a></li>
<li>改寫 MapWritable：<a href="http://blog.csdn.net/jiyuanyi1992/article/details/37739413" target="_blank" rel="external">http://blog.csdn.net/jiyuanyi1992/article/details/37739413</a></li>
</ul>
</div><!-- comment system--><div class="container"><hr><div id="disqus_thread"></div><script type="text/javascript">
var disqus_shortname = 'veckhtw';
var disqus_identifier = '2014/09/08/hadoop-co-occurrence-matrix-calculation/';
var disqus_title = '以 Hadoop 計算共現矩陣';
var disqus_url = 'http://fbukevin.github.io/Veck/2014/09/08/hadoop-co-occurrence-matrix-calculation/';
(function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">Blog comments powered by <span class="logo-disqus">Disqus</span></a></div></article><footer id="footer"><div class="container"><div class="bar"><div class="social"><a href="mailto:fbukevin@gmail.com" target="_blank"><i class="fa fa-envelope-o"></i></a><a href="http://twitter.com/VeckHsiao" target="_blank"><i class="fa fa-twitter"></i></a><a href="https://github.com/fbukevin" target="_blank"><i class="fa fa-github"></i></a><a href="/atom.xml" target="_blank"><i class="fa fa-rss"></i></a></div><div class="footer">© 2016 <a href="/" rel="nofollow">Veck's Blog</a>. Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a>. Theme <a target="_blank" href="https://github.com/lotabout/very-simple">very-simple</a>.</div></div></div></footer><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});</script></body></html>