<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>[Python] MapReduce on Hadoop - mrjob | Veck's Blog</title><link rel="stylesheet" type="text/css" href="/Veck//css/normalize.css"><link rel="stylesheet" type="text/css" href="/Veck//css/highlight.css"><link rel="stylesheet" type="text/css" href="/Veck//css/very-simple.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/Veck/favicon.ico"></head><body><!-- include the sidebar--><!-- include ./includes/sidebar.jade--><!-- Blog title and subtitle--><header><div class="container header"><a id="logo" href="/Veck/." class="title">Veck's Blog</a><span class="subtitle"></span><label id="toggle-menu" for="menu" onclick><i class="fa fa-bars"></i></label></div></header><!-- use checkbox hack for toggle nav-bar on small screens--><input id="menu" type="checkbox"><!-- Navigation Links--><nav id="nav"><div class="container"><a href="/Veck" class="sidebar-nav-item">Home</a><a href="/Veck/archives" class="sidebar-nav-item">Archives</a><a href="/Veck/about.html" class="sidebar-nav-item">About</a></div></nav><div id="header-margin-bar"></div><!-- gallery that comes before the header--><div class="wrapper"><div class="container post-header"><h1>[Python] MapReduce on Hadoop - mrjob</h1></div></div><div class="wrapper"><div class="container meta"><div class="post-time">2014-08-04</div></div></div><article><div class="container post"><ul>
<li>mrjon: <a href="https://pythonhosted.org/mrjob/" target="_blank" rel="external">https://pythonhosted.org/mrjob/</a></li>
<li>翻譯改寫自：<a href="http://mrjob.readthedocs.org/en/latest/guides/quickstart.html#writing-your-first-job" target="_blank" rel="external">http://mrjob.readthedocs.org/en/latest/guides/quickstart.html#writing-your-first-job</a></li>
</ul>
<p>用 Python 來寫 Hadoop 的 MapReduce 程式<br><a id="more"></a></p>
<ul>
<li><p>安裝：<code>pip install mrjob</code></p>
</li>
<li><p>一個官網最簡單的 word_count.py 範例：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from mrjob.job import MRJob&#10;&#10;class MRWordFrequencyCount(MRJob):&#10;    def mapper(self, _, line):&#10;        yield &#34;chars&#34;, len(line)&#10;        yield &#34;words&#34;, len(line.split())&#10;        yield &#34;lines&#34;, 1&#10;&#10;    def reducer(self, key, values):&#10;        yield key, sum(values)&#10;&#10;&#10;if __name__ == &#39;__main__&#39;:&#10;    MRWordFrequencyCount.run()</span><br></pre></td></tr></table></figure>
<ul>
<li>執行：<code>python word_count.py input.txt</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">no configs found; falling back on auto-configuration&#10;no configs found; falling back on auto-configuration&#10;creating tmp directory /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769&#10;writing to /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/step-0-mapper_part-00000&#10;Counters from step 1:&#10;  (no counters found)&#10;writing to /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/step-0-mapper-sorted&#10;&#62; sort /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/step-0-mapper_part-00000&#10;writing to /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/step-0-reducer_part-00000&#10;Counters from step 1:&#10;  (no counters found)&#10;Moving /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/step-0-reducer_part-00000 -&#62; /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/output/part-00000&#10;Streaming final output from /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769/output&#10;&#34;chars&#34;&#9;21&#10;&#34;lines&#34;&#9;1&#10;&#34;words&#34;&#9;5&#10;removing tmp directory /var/folders/bz/z8d70ds17y59ggw906xdqrvw0000gn/T/mrjob1.veck.20140804.113920.115769</span><br></pre></td></tr></table></figure>
<p>其中統計結果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#34;chars&#34; 21&#10;&#34;lines&#34;&#9;1&#10;&#34;words&#34;&#9;5</span><br></pre></td></tr></table></figure></p>
<p>程式碼中有個 <code>MRJob</code>，這個物件的 <code>class</code> 定義了你建立的 <code>job</code> 的 <code>steps</code> 中會用到的方法：<code>mapper, combiner, reducer</code>，不一定全部都要有，但每個 step 至少要有三者其中之一，也就是說，你的 job 可以只有一個 mapper、一個 combiner 或一個 reducer</p>
<p>mapper(): 吃一個 key 和一個 value 參數，並且產生許多  key-value pair，就跟原本 Java 的 Mapper 一樣<br>reducer(): 吃一個 key 和一個 iterable value，也會產生許多 key-value pair，同原本 Java 的 Reducer </p>
<p>而最後的兩行程式碼，用來驅動我們的 job：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &#39;__main__&#39;:&#10;    MRWordCounter.run()  # where MRWordCounter is your job class</span><br></pre></td></tr></table></figure></p>
<p>mrjob 預設是將 job 跑在 single python process，這樣比較方便 debug，但這樣不是分散式運算，要切換成其他的執行模式，可以加上 <code>-r</code>，共有三種不同模式：<code>-r local, -r hadoop, -r emr</code></p>
<ol>
<li>-r local: 執行在多個子行程上 (虛擬分散式)</li>
<li>-r hadoop: 執行在 hadoop 叢集上 (完全分散式)</li>
<li>-r emr: 執行在 Elastic MapReduce 上</li>
</ol>
<p>假如你的 input 檔案存放在 HDFS 或 S3 上(with EMR)：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python my_job.py -r emr s3://my-inputs/input.txt&#10;$ python my_job.py -r hadoop hdfs://my_home/input.txt</span><br></pre></td></tr></table></figure></p>
<p>假如你有多個 step (通常)在一個 job 中，你可以透過覆寫 <code>steps()</code> 方法來定義 steps，建立 <code>mrjob.step.MRStep</code> 的 <code>step list</code>，例如以下範例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from mrjob.job import MRJob&#10;from mrjob.step import MRStep&#10;import re&#10;&#10;WORD_RE = re.compile(r&#34;[\w&#39;]+&#34;)&#10;&#10;class MRMostUsedWord(MRJob):&#10;&#10;    # &#35206;&#23531; steps()&#10;    def steps(self):&#10;        return [&#10;          # &#23450;&#32681; MRStep 1&#10;          MRStep(mapper=self.mapper_get_words,&#9;# &#25351;&#23450;&#27492; step &#30340; mapper &#28858; mapper_get_words&#10;                 combiner=self.combiner_count_words,# &#25351;&#23450;&#27492; step &#30340; combiner &#28858; combiner_count_words&#10;                 reducer=self.reducer_count_words), # &#25351;&#23450;&#27492; step &#30340; reducer &#28858; reducer_count_words&#10;          # &#23450;&#32681; MRStep 2&#10;          MRStep(reducer=self.reducer_find_max_word)&#10;        ]&#10;&#10;    def mapper_get_words(self, _, line):&#10;        # yield each word in the line&#10;        for word in WORD_RE.findall(line):&#10;            yield (word.lower(), 1)&#10;&#10;    def combiner_count_words(self, word, counts):&#10;        # optimization: sum the words we&#39;ve seen so far&#10;        yield (word, sum(counts))&#10;&#10;    def reducer_count_words(self, word, counts):&#10;        # send all (num_occurrences, word) pairs to the same reducer.&#10;        # num_occurrences is so we can easily use Python&#39;s max() function.&#10;        yield None, (sum(counts), word)&#10;&#10;    # discard the key; it is just None&#10;    def reducer_find_max_word(self, _, word_count_pairs):&#10;        # each item of word_count_pairs is (count, word),&#10;        # so yielding one results in key=counts, value=word&#10;        yield max(word_count_pairs)&#10;&#10;&#10;if __name__ == &#39;__main__&#39;:&#10;    MRMostUsedWord.run()</span><br></pre></td></tr></table></figure></p>
</div><!-- comment system--><div class="container"><hr><div id="disqus_thread"></div><script type="text/javascript">
var disqus_shortname = 'vecktw';
var disqus_identifier = '2014/08/04/python-mapreduce-on-hadoop-mrjob/';
var disqus_title = '[Python] MapReduce on Hadoop - mrjob';
var disqus_url = 'http://fbukevin.github.io/Veck/2014/08/04/python-mapreduce-on-hadoop-mrjob/';
(function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">Blog comments powered by <span class="logo-disqus">Disqus</span></a></div></article><footer id="footer"><div class="container"><div class="bar"><div class="social"><a href="mailto:fbukevin@gmail.com" target="_blank"><i class="fa fa-envelope-o"></i></a><a href="http://twitter.com/VeckHsiao" target="_blank"><i class="fa fa-twitter"></i></a><a href="https://github.com/fbukevin" target="_blank"><i class="fa fa-github"></i></a><a href="/atom.xml" target="_blank"><i class="fa fa-rss"></i></a></div><div class="footer">© 2016 <a href="/" rel="nofollow">Veck's Blog</a>. Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a>. Theme <a target="_blank" href="https://github.com/lotabout/very-simple">very-simple</a>.</div></div></div></footer><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});</script></body></html>